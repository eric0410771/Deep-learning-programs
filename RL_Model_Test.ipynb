{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_Model_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0qkj-Xs5VT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optims\n",
        "import numpy as np\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpyd6suajTtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "18dd8afe-18c0-4535-fc77-4d583f1849c8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 20 10:07:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JL1BApNZbwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probability = [1.00000000e+00, \n",
        " 1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
        " 1.00000000e+00, 1.00000000e+00, 6.27850450e-57, 7.88167347e-56, 7.89730869e-48,\n",
        " 3.93009432e-53, 3.42023763e-61, 1.33541163e-27, 3.66994210e-53]\n",
        "probability = np.asarray(probability)\n",
        "prob = np.zeros((probability.shape[0], 2))\n",
        "\n",
        "prob[:,0] = probability\n",
        "prob[:,1] = 1 - probability \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3JHdV3FZhsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94af4f39-a5ad-4e20-c0c1-3be8e08fec82"
      },
      "source": [
        "fig, axs =plt.subplots(1,1, figsize = (40,40))\n",
        "clust_data = prob.T\n",
        "rowlabel=(\"P(C1|X)\", \"P(C2|X)\")\n",
        "axs.axis('off')\n",
        "axs.axis('tight')\n",
        "the_table = axs.table(cellText=clust_data ,rowLabels = rowlabel,loc='center', )\n",
        "the_table.auto_set_column_width(col=list(range(clust_data.shape[1])))\n",
        "plt.savefig('prob.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x2880 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_B-VJnP6Dg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d10083f9-6aac-415a-a7e7-d172cc93eac3"
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.state_dim = 4\n",
        "        self.conv_layer = 8\n",
        "        self.hidden_dim = 32\n",
        "        self.action_dim = 2\n",
        "        self.layer_num = 2\n",
        "        self.gamma = 0.995\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.gamma = config.gamma\n",
        "        self.action_dim = config.action_dim\n",
        "        self.evaluate_net = self.build_model(config)\n",
        "        self.target_net = self.build_model(config)\n",
        "        self.batch_size = 50\n",
        "        self.device = torch.device('cuda')\n",
        "        \n",
        "    def build_model(self,config):\n",
        "        model = nn.Sequential(nn.Linear(config.state_dim,32),nn.ReLU(),nn.Linear(32,32),nn.ReLU(),nn.Linear(32,config.action_dim))\n",
        "        return model\n",
        "    def learn(self,state_m, action_m, _state_m, reward_m):\n",
        "        state_m = torch.tensor(state_m).type('torch.FloatTensor').to(self.device)\n",
        "        action_m = torch.tensor(action_m).type('torch.LongTensor').to(self.device)\n",
        "        reward_m = torch.tensor(reward_m).type('torch.FloatTensor').to(self.device)\n",
        "        _state_m = torch.tensor(_state_m).type('torch.FloatTensor').to(self.device)\n",
        "        \n",
        "        current_value = self.evaluate_net(state_m)\n",
        "        future_value = self.target_net(_state_m)\n",
        "        max_action = np.argmax(future_value.detach().cpu().numpy(),axis = 1)\n",
        "        max_action = torch.tensor(max_action).type('torch.LongTensor').to(self.device)\n",
        "        \n",
        "        \n",
        "        difference_ = reward_m + 0.995 * future_value.gather(1,max_action.view(-1,1)) - current_value.gather(1,action_m.view(-1,1))\n",
        "\n",
        "        return torch.sum(difference_ ** 2)/difference_.size()[0]\n",
        "      \n",
        "class PolicyGradient(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.state_dim = config.state_dim\n",
        "        self.action_dim = config.action_dim\n",
        "        \n",
        "        self.layer1 = nn.Linear(self.state_dim,32)\n",
        "        self.layer2 = nn.Linear(32, self.action_dim)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "    def forward(self, input_data):\n",
        "        h1 = self.layer1(input_data)\n",
        "        h2 = self.layer2(h1)\n",
        "        return self.softmax(h2)\n",
        "      \n",
        "class Actor(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.state_dim = config.state_dim\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.layer_num = config.layer_num\n",
        "        self.action_dim = config.action_dim\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "        \n",
        "        self.layers = []\n",
        "        self.layers.append(nn.Linear(self.state_dim, self.hidden_dim))\n",
        "        self.layers.append(self.relu)\n",
        "\n",
        "        for i in range(self.layer_num):\n",
        "            self.layers.append(nn.Linear(self.hidden_dim,self.hidden_dim))\n",
        "            self.layers.append(self.relu)\n",
        "\n",
        "        self.layers.append(nn.Linear(self.hidden_dim,self.action_dim))\n",
        "        self.layers.append(self.softmax)\n",
        "        self.module = nn.Sequential(*self.layers)\n",
        "\n",
        "    def forward(self,state):\n",
        "        action_prob = self.module(state)\n",
        "        return action_prob\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.state_dim = config.state_dim\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.layer_num = config.layer_num\n",
        "        self.expacted_advantage = 1\n",
        "        self.gamma = config.gamma\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.layers = []\n",
        "        self.layers.append(nn.Linear(self.state_dim,self.hidden_dim))\n",
        "        self.layers.append(self.relu)\n",
        "        for i in range(self.layer_num):\n",
        "            self.layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
        "            self.layers.append(self.relu)\n",
        "        self.layers.append(nn.Linear(self.hidden_dim, self.expacted_advantage))\n",
        "        self.module = nn.Sequential(*self.layers)\n",
        "\n",
        "    def forward(self, state):\n",
        "        advantage = self.module(state)\n",
        "        return advantage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-99327e134228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.995\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blMIHa81CnIH",
        "colab_type": "text"
      },
      "source": [
        "##Actor Critic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDFuSk0x6j2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "974f037c-29a7-42fc-dc80-c66041830788"
      },
      "source": [
        "config = Config()\n",
        "device = torch.device('cuda')\n",
        "actor = Actor(config)\n",
        "critic = Critic(config)\n",
        "actor = actor.to(device)\n",
        "critic = critic.to(device)\n",
        "a_optim = optims.Adam(actor.module.parameters(),lr = 1e-4, weight_decay  = 1e-3)\n",
        "c_optim = optims.Adam(critic.module.parameters(),lr = 1e-3, weight_decay = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1e98a43fb190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcritic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Zv3ipE64mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discount_rewards(r):\n",
        "    discounted_r=np.zeros_like(r)\n",
        "    running_add=0\n",
        "    for t in reversed(range(len(r))):\n",
        "        running_add=running_add*0.9+r[t]\n",
        "        discounted_r[t]=running_add\n",
        "    return discounted_r\n",
        "\n",
        "\n",
        "def loss_function(state,action,state_,reward):\n",
        "    current_advantage = critic(state)\n",
        "    future_advantage = critic(state_)\n",
        "    \n",
        "    action_prob = actor(state)\n",
        "    \n",
        "    td_error = torch.tensor([reward]).type('torch.FloatTensor').to(device) - current_advantage[0]\n",
        "    action_error = -torch.log(action_prob[0,action]) * td_error\n",
        "    \n",
        "    return (td_error ** 2), action_error\n",
        "    \n",
        "def loss_function2(state_m,action_m,_state_m,reward_m,done_m):\n",
        "    #reward_m = discount_rewards(reward_m)\n",
        "    reward_m = torch.tensor(reward_m).type('torch.FloatTensor').to(device)\n",
        "    reward_m = reward_m.view(-1,1)\n",
        "    \n",
        "    state_m = torch.cat(state_m,dim = 0).to(device)\n",
        "    _state_m = torch.cat(_state_m,dim = 0).to(device)\n",
        "    done_m = torch.tensor(done_m).type('torch.FloatTensor').to(device)\n",
        "    \n",
        "    current_advantage = critic(state_m)\n",
        "    future_advantage = critic(_state_m)\n",
        "    \n",
        "    action_prob = actor(state_m)\n",
        "    action_m = torch.tensor(action_m).type('torch.LongTensor').to(device)\n",
        "    td_error = reward_m + done_m * 0.9 *torch.tensor(future_advantage.detach().cpu().numpy()).to(device) - current_advantage\n",
        "    action_error = -torch.log(action_prob.gather(1,action_m.view(-1,1))+1e-5) * td_error\n",
        "    msq_td_error = torch.mean(td_error **2)\n",
        "    action_error = torch.mean(action_error)\n",
        "    return msq_td_error + action_error\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqR75yI8bHue",
        "colab_type": "text"
      },
      "source": [
        "Actor critic不好收斂，其中使用on_policy搭配discount的reward會比用off_policy更好，off_policy的actor cirtic訓練會有問題"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlamTq6e5v4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "for i in range(10000):\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    observation = torch.tensor([observation]).type('torch.FloatTensor').to(device)\n",
        "    count = 0 \n",
        "    output = True\n",
        "    state_m = []\n",
        "    _state_m = []\n",
        "    action_m = []\n",
        "    reward_m = []\n",
        "    done_m = []\n",
        "    while not done:\n",
        "        action_prob = actor(observation)\n",
        "        action = np.random.choice(np.arange(2), p = action_prob.detach().cpu().numpy()[0])\n",
        "        observation_, reward, done,info = env.step(action)\n",
        "        observation_ = torch.tensor([observation_]).type('torch.FloatTensor').to(device)\n",
        "        if done:\n",
        "               reward = -20\n",
        "                \n",
        "        state_m.append(observation)\n",
        "        _state_m.append(observation_)\n",
        "        reward_m.append(reward)\n",
        "        action_m.append(action)\n",
        "        \n",
        "        if done:\n",
        "            done_m.append(0)\n",
        "        else:\n",
        "            done_m.append(1)\n",
        "        total_reward += reward\n",
        "        \n",
        "        observation = observation_\n",
        "    loss = loss_function2(state_m,action_m,_state_m, reward_m,done_m)\n",
        "    \n",
        "    a_optim.zero_grad()\n",
        "    c_optim.zero_grad()\n",
        "    \n",
        "    \n",
        "    loss.backward(retain_graph = True)\n",
        "    a_optim.step()\n",
        "    c_optim.step()\n",
        "    if i %10 == 0:\n",
        "        print(\"reward = \",total_reward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5xkt529C4Tv",
        "colab_type": "text"
      },
      "source": [
        "##DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4FHZxM2Yq0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config()\n",
        "device = torch.device('cuda')\n",
        "dqn = DQN(config)\n",
        "dqn = dqn.to(device)\n",
        "optim = optims.SGD(dqn.evaluate_net.parameters(),lr = 5e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJV5VMp7WJTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "epislon = 0.5\n",
        "delta = 0.00004\n",
        "count = 0\n",
        "state_m = np.zeros((500,4))\n",
        "_state_m = np.zeros((500,4))\n",
        "action_m = np.zeros((500,1),dtype = 'int32')\n",
        "reward_m = np.zeros((500,1))\n",
        "batch_size = 200\n",
        "\n",
        "for i in range(10000):\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    observation = torch.tensor([observation]).type('torch.FloatTensor').to(device)\n",
        "    output = True\n",
        "    loss = None\n",
        "    while not done:\n",
        "        action_value = dqn.evaluate_net(observation)\n",
        "        action = np.argmax(action_value.detach().cpu().numpy()[0])\n",
        "        if np.random.uniform()>epislon:\n",
        "            action = np.random.choice(2)\n",
        "          \n",
        "        \n",
        "        observation_, reward, done,info = env.step(action)\n",
        "        \n",
        "        observation_ = torch.tensor([observation_]).type('torch.FloatTensor').to(device)\n",
        "        total_reward += reward     \n",
        "        if done:\n",
        "            reward = -20\n",
        "        \n",
        "        state_m[count % 500] = observation.detach().cpu().numpy()\n",
        "        _state_m[count % 500] = observation_.detach().cpu().numpy()\n",
        "        action_m[count % 500] = action\n",
        "        reward_m[count % 500] = reward\n",
        "        \n",
        "        if count >batch_size and count % 10 == 0:\n",
        "            batch_index = np.random.choice(state_m.shape[0],batch_size)\n",
        "            loss = dqn.learn(state_m[batch_index], action_m[batch_index], _state_m[batch_index], reward_m[batch_index])\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        observation = observation_\n",
        "        count += 1\n",
        "    if i %2 == 0:\n",
        "        print(\"reward = \",total_reward)\n",
        "        dqn.target_net.load_state_dict(dqn.evaluate_net.state_dict())\n",
        "    epislon += delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8GnqM1nej-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqAuHEgmi0Cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F7gPVG2i13M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "585cddd9-2ae0-4644-f6c2-089b10055c00"
      },
      "source": [
        "print(11/4 - ((-3/4)*np.log2(3/8) + 0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.188721875540867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFWhg7e35Fvm",
        "colab_type": "text"
      },
      "source": [
        "##DQN_Priorited_Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-M0J9FT5FHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SumTree():\n",
        "    def __init__(self,capacity,state_dim):\n",
        "        self.capacity = capacity\n",
        "        self.data_index = 0\n",
        "        self.priority = np.zeros((2 * self.capacity - 1, 1))\n",
        "        self.data = np.zeros((self.capacity,2*state_dim + 2))\n",
        "    def add_leaf(self, transition, priority):\n",
        "        change = priority - self.priority[self.data_index + self.capacity - 1] \n",
        "        self.priority[self.data_index + self.capacity - 1] = priority\n",
        "        tmp = (self.data_index + self.capacity - 2)//2\n",
        "        while tmp >=0:\n",
        "\n",
        "            self.priority[tmp] += change\n",
        "            tmp = (tmp-1)//2\n",
        "        \n",
        "        self.data[self.data_index] = transition\n",
        "        self.data_index += 1\n",
        "        \n",
        "        if self.data_index >= self.capacity:\n",
        "            self.data_index %= self.capacity\n",
        "\n",
        "    def get_leaf(self, priority):\n",
        "        \n",
        "        root_index = 0\n",
        "\n",
        "        while True:\n",
        "            leaf_index = 2 * root_index + 1\n",
        "            right_index = leaf_index + 1\n",
        "            if leaf_index >= (2 * self.capacity - 1):\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                if priority <= self.priority[leaf_index]:\n",
        "                    root_index = leaf_index\n",
        "                else:\n",
        "                    root_index = right_index\n",
        "                    priority -= self.priority[leaf_index]\n",
        "        return root_index, self.priority[root_index], self.data[root_index - self.capacity+1]\n",
        "    \n",
        "    def update_leaf(self, priority_index, priority):\n",
        "        change = priority - self.priority[priority_index]\n",
        "        self.priority[priority_index] = priority\n",
        "        priority_index = (priority_index - 1)//2\n",
        "\n",
        "        while priority_index >= 0:\n",
        "            self.priority[priority_index] += change\n",
        "            priority_index = (priority_index-1)//2\n",
        "\n",
        "    def total_priority(self):\n",
        "        return self.priority[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22gbRPUPi3hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_PR():\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.gamma = config.gamma\n",
        "        self.state_dim = config.state_dim\n",
        "        self.action_dim = config.action_dim\n",
        "        self.batch_size = 50\n",
        "        self.device = torch.device('cuda')\n",
        "        self.evaluate_net = self.build_model(config).to(self.device)\n",
        "        self.target_net = self.build_model(config).to(self.device)\n",
        "        self.capacity = 500\n",
        "        self.max_abs_error = 20\n",
        "        self.sumtree = SumTree(self.capacity, config.state_dim)\n",
        "        self.beta = 0.4\n",
        "        self.alpha = 0.6\n",
        "        self.epsilon = 1e-7\n",
        "    def build_model(self,config):\n",
        "        model = nn.Sequential(nn.Linear(config.state_dim,32),nn.ReLU(),nn.Linear(32,32),nn.ReLU(),nn.Linear(32,config.action_dim))\n",
        "        return model\n",
        "    def store_transition(self,state, action, state_, reward):\n",
        "        transition = np.hstack((state.reshape(1,-1),np.asarray(action).reshape(1,1),state_.reshape(1,-1),np.asarray(reward).reshape(1,1)))\n",
        "        priority = np.abs(reward)\n",
        "        self.sumtree.add_leaf(transition, priority)\n",
        "        \n",
        "    def learn(self, batch_size = 20):\n",
        "        batch_transition = np.zeros((batch_size, 2 * self.state_dim + 2))\n",
        "        batch_priority_index = np.zeros((batch_size,)).astype('int32')\n",
        "        batch_ISWeight = np.zeros((batch_size,1))\n",
        "        \n",
        "        segment_size = self.sumtree.total_priority()/batch_size\n",
        "        \n",
        "        start_ = 0\n",
        "        \n",
        "        min_priority = np.min(self.sumtree.priority[-self.capacity:])\n",
        "        total_p = self.sumtree.total_priority()\n",
        "        for batch in range(batch_size):\n",
        "            select_priority = np.random.uniform(start_, start_+segment_size)\n",
        "            start_ = start_ + segment_size\n",
        "            priority_index, priority, transition = self.sumtree.get_leaf(select_priority)\n",
        "\n",
        "            batch_transition[batch] = transition\n",
        "            batch_priority_index[batch] = priority_index\n",
        "            batch_ISWeight[batch] = np.power(priority/total_p, -self.beta)\n",
        "            \n",
        "            \n",
        "        batch_state = batch_transition[:, :self.state_dim]\n",
        "        batch_action = batch_transition[:, self.state_dim:self.state_dim + 1]\n",
        "        batch_state_ = batch_transition[:, self.state_dim + 1:self.state_dim + 1 + self.state_dim]\n",
        "        batch_reward = batch_transition[:, self.state_dim + 1 + self.state_dim:]\n",
        "\n",
        "        batch_state = torch.tensor(batch_state).type('torch.FloatTensor').to(self.device)\n",
        "        batch_action = torch.tensor(batch_action).type('torch.LongTensor').to(self.device)\n",
        "        batch_state_ = torch.tensor(batch_state_).type('torch.FloatTensor').to(self.device)\n",
        "        batch_reward = torch.tensor(batch_reward).type('torch.FloatTensor').to(self.device)\n",
        "        batch_ISWeight = torch.tensor(batch_ISWeight).type('torch.FloatTensor').to(self.device)\n",
        "\n",
        "        current_value = self.evaluate_net(batch_state)\n",
        "        future_value = self.target_net(batch_state_)\n",
        "        max_action = np.argmax(future_value.detach().cpu().numpy(),axis = 1)\n",
        "        max_action = torch.tensor(max_action).type('torch.LongTensor').to(self.device)\n",
        "\n",
        "        td_error = batch_reward + future_value.gather(1,max_action.view(-1, 1)) - current_value.gather(1, batch_action.view(-1, 1))\n",
        "        \n",
        "        update_priority = np.abs(td_error.detach().cpu().numpy()) + self.epsilon\n",
        "        update_priority = np.minimum(self.max_abs_error, update_priority)     \n",
        "        update_priority = np.power(update_priority, self.alpha)\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            self.sumtree.update_leaf(batch_priority_index[i], update_priority[i])\n",
        "            \n",
        "        loss = torch.mean(batch_ISWeight * (td_error ** 2))\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djkJIimODemb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config()\n",
        "dqn_pr = DQN_PR(config)\n",
        "optim = optims.RMSprop(dqn_pr.evaluate_net.parameters(),lr=0.00025,eps=0.01)\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXv7k-4qDlxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b4207ea-aa9a-4fcc-f14e-60d34d23ab9a"
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "epislon = 0.1\n",
        "delta = 0.0004\n",
        "count = 0\n",
        "state_m = np.zeros((500,4))\n",
        "_state_m = np.zeros((500,4))\n",
        "action_m = np.zeros((500,1),dtype = 'int32')\n",
        "reward_m = np.zeros((500,1))\n",
        "batch_size = 200\n",
        "\n",
        "for i in range(10000):\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    observation = torch.tensor([observation]).type('torch.FloatTensor').to(device)\n",
        "    output = True\n",
        "    loss = None\n",
        "    while not done:\n",
        "        action_value = dqn_pr.evaluate_net(observation)\n",
        "        action = np.argmax(action_value.detach().cpu().numpy()[0])\n",
        "        if np.random.uniform()>epislon:\n",
        "            action = np.random.choice(2)\n",
        "          \n",
        "        \n",
        "        observation_, reward, done,info = env.step(action)\n",
        "        observation_ = torch.tensor([observation_]).type('torch.FloatTensor').to(device)    \n",
        "        \n",
        "        if done:\n",
        "            reward = -20\n",
        "        dqn_pr.store_transition(observation.detach().cpu().numpy(), action, observation_.detach().cpu().numpy(), reward)\n",
        "        if count >batch_size and count % 10 == 0:\n",
        "            loss = dqn_pr.learn()\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        total_reward += 1\n",
        "        observation = observation_\n",
        "        count += 1\n",
        "    if i %2 == 0:\n",
        "        print(\"reward = \",total_reward)\n",
        "        dqn_pr.target_net.load_state_dict(dqn_pr.evaluate_net.state_dict())\n",
        "    epislon += delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reward =  42\n",
            "reward =  17\n",
            "reward =  10\n",
            "reward =  29\n",
            "reward =  20\n",
            "reward =  16\n",
            "reward =  63\n",
            "reward =  14\n",
            "reward =  12\n",
            "reward =  15\n",
            "reward =  17\n",
            "reward =  11\n",
            "reward =  17\n",
            "reward =  27\n",
            "reward =  17\n",
            "reward =  12\n",
            "reward =  17\n",
            "reward =  28\n",
            "reward =  30\n",
            "reward =  12\n",
            "reward =  19\n",
            "reward =  14\n",
            "reward =  16\n",
            "reward =  38\n",
            "reward =  29\n",
            "reward =  51\n",
            "reward =  14\n",
            "reward =  58\n",
            "reward =  15\n",
            "reward =  31\n",
            "reward =  23\n",
            "reward =  21\n",
            "reward =  68\n",
            "reward =  20\n",
            "reward =  14\n",
            "reward =  16\n",
            "reward =  18\n",
            "reward =  13\n",
            "reward =  13\n",
            "reward =  10\n",
            "reward =  17\n",
            "reward =  18\n",
            "reward =  12\n",
            "reward =  23\n",
            "reward =  13\n",
            "reward =  21\n",
            "reward =  15\n",
            "reward =  29\n",
            "reward =  24\n",
            "reward =  21\n",
            "reward =  31\n",
            "reward =  11\n",
            "reward =  14\n",
            "reward =  30\n",
            "reward =  32\n",
            "reward =  18\n",
            "reward =  14\n",
            "reward =  15\n",
            "reward =  16\n",
            "reward =  27\n",
            "reward =  17\n",
            "reward =  16\n",
            "reward =  30\n",
            "reward =  20\n",
            "reward =  19\n",
            "reward =  18\n",
            "reward =  33\n",
            "reward =  15\n",
            "reward =  20\n",
            "reward =  12\n",
            "reward =  14\n",
            "reward =  62\n",
            "reward =  19\n",
            "reward =  12\n",
            "reward =  12\n",
            "reward =  14\n",
            "reward =  15\n",
            "reward =  11\n",
            "reward =  21\n",
            "reward =  10\n",
            "reward =  21\n",
            "reward =  35\n",
            "reward =  14\n",
            "reward =  17\n",
            "reward =  24\n",
            "reward =  59\n",
            "reward =  27\n",
            "reward =  16\n",
            "reward =  56\n",
            "reward =  22\n",
            "reward =  13\n",
            "reward =  16\n",
            "reward =  12\n",
            "reward =  44\n",
            "reward =  20\n",
            "reward =  12\n",
            "reward =  34\n",
            "reward =  12\n",
            "reward =  9\n",
            "reward =  24\n",
            "reward =  16\n",
            "reward =  11\n",
            "reward =  9\n",
            "reward =  23\n",
            "reward =  9\n",
            "reward =  37\n",
            "reward =  13\n",
            "reward =  9\n",
            "reward =  20\n",
            "reward =  11\n",
            "reward =  14\n",
            "reward =  14\n",
            "reward =  51\n",
            "reward =  13\n",
            "reward =  27\n",
            "reward =  32\n",
            "reward =  19\n",
            "reward =  11\n",
            "reward =  16\n",
            "reward =  11\n",
            "reward =  39\n",
            "reward =  18\n",
            "reward =  38\n",
            "reward =  11\n",
            "reward =  13\n",
            "reward =  13\n",
            "reward =  15\n",
            "reward =  23\n",
            "reward =  18\n",
            "reward =  10\n",
            "reward =  16\n",
            "reward =  17\n",
            "reward =  9\n",
            "reward =  21\n",
            "reward =  37\n",
            "reward =  18\n",
            "reward =  16\n",
            "reward =  13\n",
            "reward =  16\n",
            "reward =  24\n",
            "reward =  17\n",
            "reward =  25\n",
            "reward =  39\n",
            "reward =  14\n",
            "reward =  44\n",
            "reward =  23\n",
            "reward =  44\n",
            "reward =  33\n",
            "reward =  49\n",
            "reward =  72\n",
            "reward =  63\n",
            "reward =  27\n",
            "reward =  44\n",
            "reward =  27\n",
            "reward =  14\n",
            "reward =  21\n",
            "reward =  38\n",
            "reward =  35\n",
            "reward =  15\n",
            "reward =  68\n",
            "reward =  38\n",
            "reward =  25\n",
            "reward =  22\n",
            "reward =  57\n",
            "reward =  27\n",
            "reward =  35\n",
            "reward =  33\n",
            "reward =  63\n",
            "reward =  11\n",
            "reward =  13\n",
            "reward =  22\n",
            "reward =  31\n",
            "reward =  13\n",
            "reward =  18\n",
            "reward =  11\n",
            "reward =  19\n",
            "reward =  19\n",
            "reward =  48\n",
            "reward =  20\n",
            "reward =  13\n",
            "reward =  16\n",
            "reward =  25\n",
            "reward =  23\n",
            "reward =  11\n",
            "reward =  11\n",
            "reward =  19\n",
            "reward =  19\n",
            "reward =  48\n",
            "reward =  26\n",
            "reward =  49\n",
            "reward =  42\n",
            "reward =  24\n",
            "reward =  31\n",
            "reward =  20\n",
            "reward =  10\n",
            "reward =  11\n",
            "reward =  40\n",
            "reward =  45\n",
            "reward =  24\n",
            "reward =  21\n",
            "reward =  20\n",
            "reward =  19\n",
            "reward =  32\n",
            "reward =  35\n",
            "reward =  72\n",
            "reward =  30\n",
            "reward =  45\n",
            "reward =  32\n",
            "reward =  59\n",
            "reward =  13\n",
            "reward =  27\n",
            "reward =  12\n",
            "reward =  36\n",
            "reward =  43\n",
            "reward =  35\n",
            "reward =  13\n",
            "reward =  50\n",
            "reward =  84\n",
            "reward =  20\n",
            "reward =  15\n",
            "reward =  14\n",
            "reward =  43\n",
            "reward =  58\n",
            "reward =  20\n",
            "reward =  54\n",
            "reward =  34\n",
            "reward =  30\n",
            "reward =  35\n",
            "reward =  27\n",
            "reward =  13\n",
            "reward =  32\n",
            "reward =  15\n",
            "reward =  48\n",
            "reward =  35\n",
            "reward =  48\n",
            "reward =  44\n",
            "reward =  16\n",
            "reward =  12\n",
            "reward =  51\n",
            "reward =  23\n",
            "reward =  27\n",
            "reward =  21\n",
            "reward =  30\n",
            "reward =  25\n",
            "reward =  32\n",
            "reward =  11\n",
            "reward =  61\n",
            "reward =  18\n",
            "reward =  50\n",
            "reward =  43\n",
            "reward =  19\n",
            "reward =  12\n",
            "reward =  35\n",
            "reward =  35\n",
            "reward =  49\n",
            "reward =  25\n",
            "reward =  19\n",
            "reward =  15\n",
            "reward =  33\n",
            "reward =  22\n",
            "reward =  14\n",
            "reward =  24\n",
            "reward =  15\n",
            "reward =  56\n",
            "reward =  61\n",
            "reward =  17\n",
            "reward =  26\n",
            "reward =  47\n",
            "reward =  29\n",
            "reward =  27\n",
            "reward =  68\n",
            "reward =  45\n",
            "reward =  78\n",
            "reward =  45\n",
            "reward =  32\n",
            "reward =  55\n",
            "reward =  69\n",
            "reward =  22\n",
            "reward =  26\n",
            "reward =  32\n",
            "reward =  103\n",
            "reward =  110\n",
            "reward =  27\n",
            "reward =  22\n",
            "reward =  21\n",
            "reward =  21\n",
            "reward =  31\n",
            "reward =  22\n",
            "reward =  25\n",
            "reward =  45\n",
            "reward =  26\n",
            "reward =  13\n",
            "reward =  59\n",
            "reward =  75\n",
            "reward =  49\n",
            "reward =  10\n",
            "reward =  74\n",
            "reward =  119\n",
            "reward =  20\n",
            "reward =  26\n",
            "reward =  88\n",
            "reward =  33\n",
            "reward =  44\n",
            "reward =  34\n",
            "reward =  64\n",
            "reward =  18\n",
            "reward =  11\n",
            "reward =  56\n",
            "reward =  30\n",
            "reward =  82\n",
            "reward =  35\n",
            "reward =  24\n",
            "reward =  56\n",
            "reward =  10\n",
            "reward =  40\n",
            "reward =  75\n",
            "reward =  33\n",
            "reward =  26\n",
            "reward =  21\n",
            "reward =  37\n",
            "reward =  44\n",
            "reward =  14\n",
            "reward =  59\n",
            "reward =  34\n",
            "reward =  19\n",
            "reward =  59\n",
            "reward =  79\n",
            "reward =  34\n",
            "reward =  50\n",
            "reward =  53\n",
            "reward =  36\n",
            "reward =  85\n",
            "reward =  10\n",
            "reward =  58\n",
            "reward =  16\n",
            "reward =  71\n",
            "reward =  66\n",
            "reward =  24\n",
            "reward =  40\n",
            "reward =  55\n",
            "reward =  56\n",
            "reward =  122\n",
            "reward =  66\n",
            "reward =  31\n",
            "reward =  78\n",
            "reward =  51\n",
            "reward =  34\n",
            "reward =  22\n",
            "reward =  85\n",
            "reward =  19\n",
            "reward =  72\n",
            "reward =  66\n",
            "reward =  38\n",
            "reward =  76\n",
            "reward =  56\n",
            "reward =  47\n",
            "reward =  83\n",
            "reward =  37\n",
            "reward =  47\n",
            "reward =  41\n",
            "reward =  26\n",
            "reward =  129\n",
            "reward =  34\n",
            "reward =  49\n",
            "reward =  52\n",
            "reward =  33\n",
            "reward =  36\n",
            "reward =  30\n",
            "reward =  38\n",
            "reward =  52\n",
            "reward =  26\n",
            "reward =  93\n",
            "reward =  19\n",
            "reward =  99\n",
            "reward =  48\n",
            "reward =  96\n",
            "reward =  60\n",
            "reward =  72\n",
            "reward =  31\n",
            "reward =  90\n",
            "reward =  77\n",
            "reward =  59\n",
            "reward =  93\n",
            "reward =  37\n",
            "reward =  35\n",
            "reward =  56\n",
            "reward =  58\n",
            "reward =  80\n",
            "reward =  30\n",
            "reward =  39\n",
            "reward =  19\n",
            "reward =  166\n",
            "reward =  51\n",
            "reward =  77\n",
            "reward =  23\n",
            "reward =  64\n",
            "reward =  101\n",
            "reward =  41\n",
            "reward =  99\n",
            "reward =  49\n",
            "reward =  34\n",
            "reward =  60\n",
            "reward =  84\n",
            "reward =  85\n",
            "reward =  36\n",
            "reward =  72\n",
            "reward =  74\n",
            "reward =  89\n",
            "reward =  69\n",
            "reward =  35\n",
            "reward =  38\n",
            "reward =  104\n",
            "reward =  34\n",
            "reward =  62\n",
            "reward =  86\n",
            "reward =  40\n",
            "reward =  38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-dfbab2d9d5b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mobservation_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mobservation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobservation_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torch.FloatTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpCQHGwJIyx4",
        "colab_type": "text"
      },
      "source": [
        "注意當發現reward出現問題(隨著訓練往下降)，除了是"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK_ndi3AhUPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config()\n",
        "pg = PolicyGradient(config)\n",
        "device = torch.device('cuda')\n",
        "pg = pg.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKDSWIIm-Cnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "epislon = 0.5\n",
        "delta = 0.00004\n",
        "count = 0\n",
        "batch_size = 200\n",
        "\n",
        "for i in range(10000):\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    observation = torch.tensor([observation]).type('torch.FloatTensor').to(device)\n",
        "    output = True\n",
        "    loss = None\n",
        "    while not done:\n",
        "        action_value = pg(observation)\n",
        "        action_value = action_value.detach().cpu().numpy()\n",
        "        action = np.random.choice(len(action_value),p = action_value)\n",
        "         \n",
        "        observation_, reward, done,info = env.step(action)\n",
        "        observation_ = torch.tensor([observation_]).type('torch.FloatTensor').to(device)    \n",
        "        \n",
        "        if done:\n",
        "            reward = -20\n",
        "        dqn_pr.store_transition(observation.detach().cpu().numpy(), action, observation_.detach().cpu().numpy(), reward)\n",
        "        if count >batch_size and count % 10 == 0:\n",
        "            loss = dqn_pr.learn()\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        total_reward += 1\n",
        "        observation = observation_\n",
        "        count += 1\n",
        "    if i %2 == 0:\n",
        "        print(\"reward = \",total_reward)\n",
        "        dqn_pr.target_net.load_state_dict(dqn_pr.evaluate_net.state_dict())\n",
        "    epislon += delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb6VBOmQtICU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SumTree():\n",
        "    def __init__(self,capacity,state_dim):\n",
        "        self.capacity = capacity\n",
        "        self.data_index = 0\n",
        "        self.priority = np.zeros((2 * self.capacity - 1, 1))\n",
        "        self.data = np.zeros((self.capacity,2*state_dim + 3))\n",
        "    def add_leaf(self, transition, priority):\n",
        "        change = priority - self.priority[self.data_index + self.capacity - 1] \n",
        "        self.priority[self.data_index + self.capacity - 1] = priority\n",
        "        tmp = (self.data_index + self.capacity - 2)//2\n",
        "        while tmp >=0:\n",
        "\n",
        "            self.priority[tmp] += change\n",
        "            tmp = (tmp-1)//2\n",
        "        \n",
        "        self.data[self.data_index] = transition\n",
        "        self.data_index += 1\n",
        "        \n",
        "        if self.data_index >= self.capacity:\n",
        "            self.data_index %= self.capacity\n",
        "\n",
        "    def get_leaf(self, priority):\n",
        "        \n",
        "        root_index = 0\n",
        "\n",
        "        while True:\n",
        "            leaf_index = 2 * root_index + 1\n",
        "            right_index = leaf_index + 1\n",
        "            if leaf_index >= (2 * self.capacity - 1):\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                if priority <= self.priority[leaf_index]:\n",
        "                    root_index = leaf_index\n",
        "                else:\n",
        "                    root_index = right_index\n",
        "                    priority -= self.priority[leaf_index]\n",
        "        return root_index, self.priority[root_index], self.data[root_index - self.capacity+1]\n",
        "    \n",
        "    def update_leaf(self, priority_index, priority):\n",
        "        change = priority - self.priority[priority_index]\n",
        "        self.priority[priority_index] = priority\n",
        "        priority_index = (priority_index - 1)//2\n",
        "\n",
        "        while priority_index >= 0:\n",
        "            self.priority[priority_index] += change\n",
        "            priority_index = (priority_index-1)//2\n",
        "\n",
        "    def total_priority(self):\n",
        "        return self.priority[0]\n",
        "class DQN_PR():\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.gamma = config.gamma\n",
        "        self.state_dim = config.state_dim\n",
        "        self.action_dim = config.action_dim\n",
        "        self.batch_size = 50\n",
        "        self.device = torch.device('cuda')\n",
        "        self.evaluate_net = self.build_model(config).to(self.device)\n",
        "        self.target_net = self.build_model(config).to(self.device)\n",
        "        self.capacity = 500\n",
        "        self.max_abs_error = 20\n",
        "        self.sumtree = SumTree(self.capacity, config.state_dim)\n",
        "        self.beta = 0.4\n",
        "        self.alpha = 0.6\n",
        "        self.epsilon = 1e-7\n",
        "    def build_model(self,config):\n",
        "        model = nn.Sequential(nn.Linear(config.state_dim,32),nn.ReLU(),nn.Linear(32,32),nn.ReLU(),nn.Linear(32,config.action_dim))\n",
        "        return model\n",
        "    def store_transition(self,state, action, state_, reward, done):\n",
        "        transition = np.hstack((state.reshape(1,-1),np.asarray(action).reshape(1,1),state_.reshape(1,-1),np.asarray(reward).reshape(1,1), np.asarray(done).reshape(1,1)))\n",
        "                               \n",
        "        priority = np.abs(reward)\n",
        "        self.sumtree.add_leaf(transition, priority)\n",
        "        \n",
        "    def learn(self, batch_size = 20):\n",
        "        batch_transition = np.zeros((batch_size, 2 * self.state_dim + 3))\n",
        "        batch_priority_index = np.zeros((batch_size,)).astype('int32')\n",
        "        batch_ISWeight = np.zeros((batch_size,1))\n",
        "        \n",
        "        segment_size = self.sumtree.total_priority()/batch_size\n",
        "        \n",
        "        start_ = 0\n",
        "        \n",
        "        min_priority = np.min(self.sumtree.priority[-self.capacity:])\n",
        "        total_p = self.sumtree.total_priority()\n",
        "        for batch in range(batch_size):\n",
        "            select_priority = np.random.uniform(start_, start_+segment_size)\n",
        "            start_ = start_ + segment_size\n",
        "            priority_index, priority, transition = self.sumtree.get_leaf(select_priority)\n",
        "\n",
        "            batch_transition[batch] = transition\n",
        "            batch_priority_index[batch] = priority_index\n",
        "            batch_ISWeight[batch] = np.power(priority/total_p, -self.beta)\n",
        "            \n",
        "            \n",
        "        batch_state = batch_transition[:, :self.state_dim]\n",
        "        batch_action = batch_transition[:, self.state_dim:self.state_dim + 1]\n",
        "        batch_state_ = batch_transition[:, self.state_dim + 1:self.state_dim + 1 + self.state_dim]\n",
        "        batch_reward = batch_transition[:, self.state_dim + 1 + self.state_dim: 2 * self.state_dim + 2]\n",
        "        batch_done = batch_transition[:, 2 * self.state_dim + 2:]\n",
        "        \n",
        "        batch_state = torch.tensor(batch_state).type('torch.FloatTensor').to(self.device)\n",
        "        batch_action = torch.tensor(batch_action).type('torch.LongTensor').to(self.device)\n",
        "        batch_state_ = torch.tensor(batch_state_).type('torch.FloatTensor').to(self.device)\n",
        "        batch_reward = torch.tensor(batch_reward).type('torch.FloatTensor').to(self.device)\n",
        "        batch_done = torch.tensor(batch_done).type(torch.FloatTensor).to(self.device)\n",
        "        batch_ISWeight = torch.tensor(batch_ISWeight).type('torch.FloatTensor').to(self.device)\n",
        "\n",
        "        current_value = self.evaluate_net(batch_state)\n",
        "        future_value = self.target_net(batch_state_)\n",
        "        max_action = np.argmax(future_value.detach().cpu().numpy(),axis = 1)\n",
        "        max_action = torch.tensor(max_action).type('torch.LongTensor').to(self.device)\n",
        "\n",
        "        td_error = batch_reward + future_value.gather(1,max_action.view(-1, 1)) * batch_done - current_value.gather(1, batch_action.view(-1, 1))\n",
        "        \n",
        "        update_priority = np.abs(td_error.detach().cpu().numpy()) + self.epsilon\n",
        "        update_priority = np.minimum(self.max_abs_error, update_priority)     \n",
        "        update_priority = np.power(update_priority, self.alpha)\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            self.sumtree.update_leaf(batch_priority_index[i], update_priority[i])\n",
        "            \n",
        "        loss = torch.mean(batch_ISWeight * (td_error ** 2))\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05dtHGTtxM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config()\n",
        "dqn_pr = DQN_PR(config)\n",
        "optim = optims.RMSprop(dqn_pr.evaluate_net.parameters(),lr=0.00025,eps=0.01)\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OIQkS8etNB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a11bd791-9639-4c7b-cc77-62ac3936d200"
      },
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "epislon = 0.1\n",
        "delta = 0.0004\n",
        "count = 0\n",
        "state_m = np.zeros((500,4))\n",
        "_state_m = np.zeros((500,4))\n",
        "action_m = np.zeros((500,1),dtype = 'int32')\n",
        "reward_m = np.zeros((500,1))\n",
        "batch_size = 200\n",
        "\n",
        "for i in range(2000):\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    observation = env.reset()\n",
        "    observation = torch.tensor([observation]).type('torch.FloatTensor').to(device)\n",
        "    output = True\n",
        "    loss = None\n",
        "    while not done:\n",
        "        action_value = dqn_pr.evaluate_net(observation)\n",
        "        action = np.argmax(action_value.detach().cpu().numpy()[0])\n",
        "        if np.random.uniform()>epislon:\n",
        "            action = np.random.choice(2)\n",
        "          \n",
        "        \n",
        "        observation_, reward, done,info = env.step(action)\n",
        "        observation_ = torch.tensor([observation_]).type('torch.FloatTensor').to(device)    \n",
        "        \n",
        "        if done:\n",
        "            reward = -20\n",
        "            dqn_pr.store_transition(observation.detach().cpu().numpy(), action, observation_.detach().cpu().numpy(), reward, 0.0)\n",
        "        else:\n",
        "            dqn_pr.store_transition(observation.detach().cpu().numpy(), action, observation_.detach().cpu().numpy(), reward, 1.0)\n",
        "        if count >batch_size and count % 10 == 0:\n",
        "            loss = dqn_pr.learn()\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        total_reward += 1\n",
        "        observation = observation_\n",
        "        count += 1\n",
        "    if i %2 == 0:\n",
        "        print(\"reward = \",total_reward)\n",
        "        dqn_pr.target_net.load_state_dict(dqn_pr.evaluate_net.state_dict())\n",
        "    epislon += delta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reward =  23\n",
            "reward =  24\n",
            "reward =  21\n",
            "reward =  34\n",
            "reward =  16\n",
            "reward =  17\n",
            "reward =  13\n",
            "reward =  11\n",
            "reward =  32\n",
            "reward =  36\n",
            "reward =  11\n",
            "reward =  15\n",
            "reward =  13\n",
            "reward =  10\n",
            "reward =  27\n",
            "reward =  19\n",
            "reward =  10\n",
            "reward =  26\n",
            "reward =  13\n",
            "reward =  9\n",
            "reward =  13\n",
            "reward =  16\n",
            "reward =  41\n",
            "reward =  13\n",
            "reward =  10\n",
            "reward =  20\n",
            "reward =  40\n",
            "reward =  18\n",
            "reward =  15\n",
            "reward =  25\n",
            "reward =  14\n",
            "reward =  47\n",
            "reward =  16\n",
            "reward =  33\n",
            "reward =  31\n",
            "reward =  12\n",
            "reward =  15\n",
            "reward =  35\n",
            "reward =  38\n",
            "reward =  13\n",
            "reward =  21\n",
            "reward =  19\n",
            "reward =  17\n",
            "reward =  39\n",
            "reward =  17\n",
            "reward =  12\n",
            "reward =  14\n",
            "reward =  11\n",
            "reward =  18\n",
            "reward =  25\n",
            "reward =  17\n",
            "reward =  28\n",
            "reward =  34\n",
            "reward =  13\n",
            "reward =  19\n",
            "reward =  21\n",
            "reward =  36\n",
            "reward =  9\n",
            "reward =  10\n",
            "reward =  17\n",
            "reward =  14\n",
            "reward =  21\n",
            "reward =  10\n",
            "reward =  15\n",
            "reward =  11\n",
            "reward =  13\n",
            "reward =  66\n",
            "reward =  31\n",
            "reward =  39\n",
            "reward =  11\n",
            "reward =  30\n",
            "reward =  15\n",
            "reward =  13\n",
            "reward =  40\n",
            "reward =  21\n",
            "reward =  14\n",
            "reward =  41\n",
            "reward =  9\n",
            "reward =  24\n",
            "reward =  29\n",
            "reward =  14\n",
            "reward =  11\n",
            "reward =  69\n",
            "reward =  13\n",
            "reward =  38\n",
            "reward =  23\n",
            "reward =  20\n",
            "reward =  10\n",
            "reward =  29\n",
            "reward =  18\n",
            "reward =  13\n",
            "reward =  28\n",
            "reward =  10\n",
            "reward =  24\n",
            "reward =  12\n",
            "reward =  47\n",
            "reward =  28\n",
            "reward =  14\n",
            "reward =  18\n",
            "reward =  16\n",
            "reward =  10\n",
            "reward =  16\n",
            "reward =  18\n",
            "reward =  11\n",
            "reward =  19\n",
            "reward =  29\n",
            "reward =  19\n",
            "reward =  9\n",
            "reward =  9\n",
            "reward =  15\n",
            "reward =  28\n",
            "reward =  11\n",
            "reward =  35\n",
            "reward =  20\n",
            "reward =  12\n",
            "reward =  12\n",
            "reward =  15\n",
            "reward =  15\n",
            "reward =  19\n",
            "reward =  11\n",
            "reward =  14\n",
            "reward =  19\n",
            "reward =  23\n",
            "reward =  10\n",
            "reward =  12\n",
            "reward =  45\n",
            "reward =  11\n",
            "reward =  14\n",
            "reward =  10\n",
            "reward =  14\n",
            "reward =  25\n",
            "reward =  18\n",
            "reward =  20\n",
            "reward =  14\n",
            "reward =  15\n",
            "reward =  20\n",
            "reward =  9\n",
            "reward =  17\n",
            "reward =  12\n",
            "reward =  38\n",
            "reward =  14\n",
            "reward =  10\n",
            "reward =  17\n",
            "reward =  15\n",
            "reward =  9\n",
            "reward =  16\n",
            "reward =  18\n",
            "reward =  10\n",
            "reward =  12\n",
            "reward =  12\n",
            "reward =  15\n",
            "reward =  13\n",
            "reward =  12\n",
            "reward =  17\n",
            "reward =  18\n",
            "reward =  10\n",
            "reward =  13\n",
            "reward =  15\n",
            "reward =  14\n",
            "reward =  13\n",
            "reward =  31\n",
            "reward =  10\n",
            "reward =  10\n",
            "reward =  11\n",
            "reward =  14\n",
            "reward =  14\n",
            "reward =  16\n",
            "reward =  17\n",
            "reward =  23\n",
            "reward =  21\n",
            "reward =  13\n",
            "reward =  14\n",
            "reward =  12\n",
            "reward =  9\n",
            "reward =  15\n",
            "reward =  14\n",
            "reward =  16\n",
            "reward =  15\n",
            "reward =  24\n",
            "reward =  13\n",
            "reward =  14\n",
            "reward =  15\n",
            "reward =  14\n",
            "reward =  18\n",
            "reward =  11\n",
            "reward =  16\n",
            "reward =  16\n",
            "reward =  19\n",
            "reward =  36\n",
            "reward =  12\n",
            "reward =  9\n",
            "reward =  9\n",
            "reward =  19\n",
            "reward =  8\n",
            "reward =  33\n",
            "reward =  23\n",
            "reward =  11\n",
            "reward =  18\n",
            "reward =  16\n",
            "reward =  55\n",
            "reward =  36\n",
            "reward =  12\n",
            "reward =  32\n",
            "reward =  14\n",
            "reward =  13\n",
            "reward =  18\n",
            "reward =  24\n",
            "reward =  15\n",
            "reward =  17\n",
            "reward =  19\n",
            "reward =  15\n",
            "reward =  23\n",
            "reward =  11\n",
            "reward =  25\n",
            "reward =  23\n",
            "reward =  26\n",
            "reward =  16\n",
            "reward =  13\n",
            "reward =  13\n",
            "reward =  23\n",
            "reward =  14\n",
            "reward =  14\n",
            "reward =  21\n",
            "reward =  36\n",
            "reward =  67\n",
            "reward =  24\n",
            "reward =  15\n",
            "reward =  27\n",
            "reward =  35\n",
            "reward =  21\n",
            "reward =  127\n",
            "reward =  38\n",
            "reward =  43\n",
            "reward =  38\n",
            "reward =  13\n",
            "reward =  43\n",
            "reward =  41\n",
            "reward =  61\n",
            "reward =  36\n",
            "reward =  10\n",
            "reward =  30\n",
            "reward =  25\n",
            "reward =  28\n",
            "reward =  46\n",
            "reward =  66\n",
            "reward =  165\n",
            "reward =  21\n",
            "reward =  17\n",
            "reward =  52\n",
            "reward =  45\n",
            "reward =  82\n",
            "reward =  75\n",
            "reward =  35\n",
            "reward =  30\n",
            "reward =  44\n",
            "reward =  43\n",
            "reward =  18\n",
            "reward =  30\n",
            "reward =  31\n",
            "reward =  26\n",
            "reward =  28\n",
            "reward =  72\n",
            "reward =  24\n",
            "reward =  20\n",
            "reward =  44\n",
            "reward =  57\n",
            "reward =  19\n",
            "reward =  29\n",
            "reward =  44\n",
            "reward =  56\n",
            "reward =  61\n",
            "reward =  25\n",
            "reward =  25\n",
            "reward =  28\n",
            "reward =  19\n",
            "reward =  17\n",
            "reward =  41\n",
            "reward =  47\n",
            "reward =  90\n",
            "reward =  43\n",
            "reward =  75\n",
            "reward =  92\n",
            "reward =  13\n",
            "reward =  35\n",
            "reward =  44\n",
            "reward =  100\n",
            "reward =  39\n",
            "reward =  59\n",
            "reward =  56\n",
            "reward =  37\n",
            "reward =  19\n",
            "reward =  86\n",
            "reward =  28\n",
            "reward =  13\n",
            "reward =  136\n",
            "reward =  18\n",
            "reward =  38\n",
            "reward =  35\n",
            "reward =  37\n",
            "reward =  71\n",
            "reward =  29\n",
            "reward =  41\n",
            "reward =  67\n",
            "reward =  27\n",
            "reward =  26\n",
            "reward =  53\n",
            "reward =  55\n",
            "reward =  16\n",
            "reward =  16\n",
            "reward =  41\n",
            "reward =  21\n",
            "reward =  103\n",
            "reward =  46\n",
            "reward =  63\n",
            "reward =  20\n",
            "reward =  62\n",
            "reward =  44\n",
            "reward =  71\n",
            "reward =  45\n",
            "reward =  38\n",
            "reward =  90\n",
            "reward =  99\n",
            "reward =  115\n",
            "reward =  111\n",
            "reward =  52\n",
            "reward =  27\n",
            "reward =  146\n",
            "reward =  51\n",
            "reward =  98\n",
            "reward =  15\n",
            "reward =  26\n",
            "reward =  61\n",
            "reward =  125\n",
            "reward =  83\n",
            "reward =  85\n",
            "reward =  248\n",
            "reward =  29\n",
            "reward =  61\n",
            "reward =  121\n",
            "reward =  41\n",
            "reward =  121\n",
            "reward =  41\n",
            "reward =  24\n",
            "reward =  17\n",
            "reward =  18\n",
            "reward =  38\n",
            "reward =  32\n",
            "reward =  80\n",
            "reward =  18\n",
            "reward =  55\n",
            "reward =  73\n",
            "reward =  26\n",
            "reward =  37\n",
            "reward =  65\n",
            "reward =  31\n",
            "reward =  55\n",
            "reward =  134\n",
            "reward =  105\n",
            "reward =  40\n",
            "reward =  81\n",
            "reward =  44\n",
            "reward =  31\n",
            "reward =  151\n",
            "reward =  57\n",
            "reward =  39\n",
            "reward =  112\n",
            "reward =  24\n",
            "reward =  39\n",
            "reward =  83\n",
            "reward =  34\n",
            "reward =  12\n",
            "reward =  16\n",
            "reward =  66\n",
            "reward =  55\n",
            "reward =  95\n",
            "reward =  10\n",
            "reward =  56\n",
            "reward =  42\n",
            "reward =  71\n",
            "reward =  193\n",
            "reward =  97\n",
            "reward =  73\n",
            "reward =  65\n",
            "reward =  25\n",
            "reward =  85\n",
            "reward =  59\n",
            "reward =  20\n",
            "reward =  85\n",
            "reward =  17\n",
            "reward =  156\n",
            "reward =  126\n",
            "reward =  124\n",
            "reward =  211\n",
            "reward =  127\n",
            "reward =  85\n",
            "reward =  68\n",
            "reward =  34\n",
            "reward =  19\n",
            "reward =  289\n",
            "reward =  58\n",
            "reward =  240\n",
            "reward =  45\n",
            "reward =  206\n",
            "reward =  285\n",
            "reward =  209\n",
            "reward =  53\n",
            "reward =  24\n",
            "reward =  66\n",
            "reward =  137\n",
            "reward =  79\n",
            "reward =  12\n",
            "reward =  60\n",
            "reward =  47\n",
            "reward =  41\n",
            "reward =  91\n",
            "reward =  36\n",
            "reward =  62\n",
            "reward =  39\n",
            "reward =  55\n",
            "reward =  39\n",
            "reward =  47\n",
            "reward =  128\n",
            "reward =  99\n",
            "reward =  150\n",
            "reward =  42\n",
            "reward =  26\n",
            "reward =  81\n",
            "reward =  58\n",
            "reward =  153\n",
            "reward =  62\n",
            "reward =  182\n",
            "reward =  63\n",
            "reward =  68\n",
            "reward =  80\n",
            "reward =  24\n",
            "reward =  38\n",
            "reward =  52\n",
            "reward =  64\n",
            "reward =  16\n",
            "reward =  17\n",
            "reward =  95\n",
            "reward =  102\n",
            "reward =  73\n",
            "reward =  251\n",
            "reward =  77\n",
            "reward =  58\n",
            "reward =  125\n",
            "reward =  56\n",
            "reward =  35\n",
            "reward =  99\n",
            "reward =  55\n",
            "reward =  64\n",
            "reward =  32\n",
            "reward =  125\n",
            "reward =  110\n",
            "reward =  132\n",
            "reward =  163\n",
            "reward =  96\n",
            "reward =  253\n",
            "reward =  33\n",
            "reward =  47\n",
            "reward =  75\n",
            "reward =  188\n",
            "reward =  87\n",
            "reward =  131\n",
            "reward =  222\n",
            "reward =  144\n",
            "reward =  38\n",
            "reward =  68\n",
            "reward =  132\n",
            "reward =  54\n",
            "reward =  121\n",
            "reward =  57\n",
            "reward =  270\n",
            "reward =  41\n",
            "reward =  93\n",
            "reward =  129\n",
            "reward =  204\n",
            "reward =  18\n",
            "reward =  61\n",
            "reward =  149\n",
            "reward =  74\n",
            "reward =  65\n",
            "reward =  98\n",
            "reward =  25\n",
            "reward =  34\n",
            "reward =  11\n",
            "reward =  76\n",
            "reward =  80\n",
            "reward =  162\n",
            "reward =  156\n",
            "reward =  63\n",
            "reward =  310\n",
            "reward =  20\n",
            "reward =  145\n",
            "reward =  370\n",
            "reward =  18\n",
            "reward =  51\n",
            "reward =  29\n",
            "reward =  371\n",
            "reward =  20\n",
            "reward =  152\n",
            "reward =  87\n",
            "reward =  44\n",
            "reward =  25\n",
            "reward =  231\n",
            "reward =  43\n",
            "reward =  81\n",
            "reward =  28\n",
            "reward =  136\n",
            "reward =  41\n",
            "reward =  252\n",
            "reward =  69\n",
            "reward =  153\n",
            "reward =  93\n",
            "reward =  167\n",
            "reward =  94\n",
            "reward =  124\n",
            "reward =  23\n",
            "reward =  72\n",
            "reward =  178\n",
            "reward =  13\n",
            "reward =  130\n",
            "reward =  101\n",
            "reward =  221\n",
            "reward =  127\n",
            "reward =  180\n",
            "reward =  227\n",
            "reward =  206\n",
            "reward =  159\n",
            "reward =  32\n",
            "reward =  66\n",
            "reward =  78\n",
            "reward =  205\n",
            "reward =  142\n",
            "reward =  172\n",
            "reward =  177\n",
            "reward =  11\n",
            "reward =  33\n",
            "reward =  65\n",
            "reward =  44\n",
            "reward =  192\n",
            "reward =  204\n",
            "reward =  135\n",
            "reward =  89\n",
            "reward =  88\n",
            "reward =  285\n",
            "reward =  42\n",
            "reward =  336\n",
            "reward =  131\n",
            "reward =  119\n",
            "reward =  133\n",
            "reward =  247\n",
            "reward =  274\n",
            "reward =  174\n",
            "reward =  171\n",
            "reward =  178\n",
            "reward =  307\n",
            "reward =  22\n",
            "reward =  49\n",
            "reward =  229\n",
            "reward =  56\n",
            "reward =  130\n",
            "reward =  112\n",
            "reward =  197\n",
            "reward =  129\n",
            "reward =  57\n",
            "reward =  29\n",
            "reward =  139\n",
            "reward =  185\n",
            "reward =  85\n",
            "reward =  38\n",
            "reward =  173\n",
            "reward =  492\n",
            "reward =  152\n",
            "reward =  349\n",
            "reward =  126\n",
            "reward =  166\n",
            "reward =  245\n",
            "reward =  163\n",
            "reward =  33\n",
            "reward =  50\n",
            "reward =  154\n",
            "reward =  177\n",
            "reward =  103\n",
            "reward =  183\n",
            "reward =  110\n",
            "reward =  239\n",
            "reward =  267\n",
            "reward =  220\n",
            "reward =  55\n",
            "reward =  109\n",
            "reward =  119\n",
            "reward =  74\n",
            "reward =  21\n",
            "reward =  97\n",
            "reward =  28\n",
            "reward =  64\n",
            "reward =  165\n",
            "reward =  138\n",
            "reward =  26\n",
            "reward =  23\n",
            "reward =  205\n",
            "reward =  223\n",
            "reward =  14\n",
            "reward =  126\n",
            "reward =  33\n",
            "reward =  51\n",
            "reward =  15\n",
            "reward =  193\n",
            "reward =  157\n",
            "reward =  138\n",
            "reward =  240\n",
            "reward =  92\n",
            "reward =  361\n",
            "reward =  28\n",
            "reward =  244\n",
            "reward =  26\n",
            "reward =  32\n",
            "reward =  233\n",
            "reward =  100\n",
            "reward =  295\n",
            "reward =  68\n",
            "reward =  138\n",
            "reward =  142\n",
            "reward =  185\n",
            "reward =  31\n",
            "reward =  269\n",
            "reward =  230\n",
            "reward =  217\n",
            "reward =  91\n",
            "reward =  113\n",
            "reward =  248\n",
            "reward =  72\n",
            "reward =  196\n",
            "reward =  205\n",
            "reward =  182\n",
            "reward =  63\n",
            "reward =  500\n",
            "reward =  192\n",
            "reward =  239\n",
            "reward =  179\n",
            "reward =  46\n",
            "reward =  341\n",
            "reward =  390\n",
            "reward =  138\n",
            "reward =  227\n",
            "reward =  168\n",
            "reward =  399\n",
            "reward =  102\n",
            "reward =  173\n",
            "reward =  72\n",
            "reward =  188\n",
            "reward =  140\n",
            "reward =  44\n",
            "reward =  212\n",
            "reward =  341\n",
            "reward =  229\n",
            "reward =  53\n",
            "reward =  205\n",
            "reward =  144\n",
            "reward =  132\n",
            "reward =  217\n",
            "reward =  256\n",
            "reward =  125\n",
            "reward =  247\n",
            "reward =  264\n",
            "reward =  239\n",
            "reward =  149\n",
            "reward =  318\n",
            "reward =  265\n",
            "reward =  317\n",
            "reward =  347\n",
            "reward =  369\n",
            "reward =  409\n",
            "reward =  210\n",
            "reward =  208\n",
            "reward =  34\n",
            "reward =  182\n",
            "reward =  281\n",
            "reward =  199\n",
            "reward =  191\n",
            "reward =  255\n",
            "reward =  234\n",
            "reward =  84\n",
            "reward =  178\n",
            "reward =  227\n",
            "reward =  281\n",
            "reward =  191\n",
            "reward =  229\n",
            "reward =  211\n",
            "reward =  203\n",
            "reward =  194\n",
            "reward =  117\n",
            "reward =  181\n",
            "reward =  202\n",
            "reward =  62\n",
            "reward =  42\n",
            "reward =  91\n",
            "reward =  135\n",
            "reward =  94\n",
            "reward =  184\n",
            "reward =  245\n",
            "reward =  126\n",
            "reward =  197\n",
            "reward =  184\n",
            "reward =  147\n",
            "reward =  177\n",
            "reward =  128\n",
            "reward =  126\n",
            "reward =  170\n",
            "reward =  129\n",
            "reward =  231\n",
            "reward =  244\n",
            "reward =  129\n",
            "reward =  110\n",
            "reward =  298\n",
            "reward =  334\n",
            "reward =  251\n",
            "reward =  318\n",
            "reward =  257\n",
            "reward =  124\n",
            "reward =  160\n",
            "reward =  197\n",
            "reward =  289\n",
            "reward =  176\n",
            "reward =  161\n",
            "reward =  293\n",
            "reward =  328\n",
            "reward =  148\n",
            "reward =  152\n",
            "reward =  264\n",
            "reward =  153\n",
            "reward =  243\n",
            "reward =  136\n",
            "reward =  138\n",
            "reward =  146\n",
            "reward =  171\n",
            "reward =  225\n",
            "reward =  232\n",
            "reward =  147\n",
            "reward =  126\n",
            "reward =  59\n",
            "reward =  185\n",
            "reward =  202\n",
            "reward =  181\n",
            "reward =  401\n",
            "reward =  398\n",
            "reward =  97\n",
            "reward =  236\n",
            "reward =  296\n",
            "reward =  177\n",
            "reward =  246\n",
            "reward =  232\n",
            "reward =  377\n",
            "reward =  149\n",
            "reward =  153\n",
            "reward =  344\n",
            "reward =  301\n",
            "reward =  215\n",
            "reward =  132\n",
            "reward =  343\n",
            "reward =  404\n",
            "reward =  284\n",
            "reward =  314\n",
            "reward =  324\n",
            "reward =  357\n",
            "reward =  98\n",
            "reward =  174\n",
            "reward =  281\n",
            "reward =  206\n",
            "reward =  196\n",
            "reward =  156\n",
            "reward =  142\n",
            "reward =  196\n",
            "reward =  165\n",
            "reward =  317\n",
            "reward =  157\n",
            "reward =  287\n",
            "reward =  222\n",
            "reward =  121\n",
            "reward =  94\n",
            "reward =  308\n",
            "reward =  367\n",
            "reward =  260\n",
            "reward =  154\n",
            "reward =  154\n",
            "reward =  209\n",
            "reward =  148\n",
            "reward =  183\n",
            "reward =  398\n",
            "reward =  211\n",
            "reward =  141\n",
            "reward =  416\n",
            "reward =  95\n",
            "reward =  299\n",
            "reward =  82\n",
            "reward =  103\n",
            "reward =  288\n",
            "reward =  114\n",
            "reward =  398\n",
            "reward =  131\n",
            "reward =  358\n",
            "reward =  204\n",
            "reward =  307\n",
            "reward =  274\n",
            "reward =  250\n",
            "reward =  228\n",
            "reward =  270\n",
            "reward =  229\n",
            "reward =  213\n",
            "reward =  265\n",
            "reward =  175\n",
            "reward =  134\n",
            "reward =  220\n",
            "reward =  318\n",
            "reward =  159\n",
            "reward =  209\n",
            "reward =  180\n",
            "reward =  279\n",
            "reward =  276\n",
            "reward =  500\n",
            "reward =  152\n",
            "reward =  229\n",
            "reward =  322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1349c1121eaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn_pr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}